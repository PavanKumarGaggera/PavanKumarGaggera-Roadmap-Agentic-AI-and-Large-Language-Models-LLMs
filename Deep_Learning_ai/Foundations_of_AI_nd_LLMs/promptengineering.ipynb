{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGpt Prompt Engineering For Developers\n",
    "\n",
    "In this notebook, you will learn:\n",
    "* Guidelines For Prompting\n",
    "* Iterative Prompt Development\n",
    "* Summarizing\n",
    "* Inferring\n",
    "* Transforming\n",
    "* Expanding\n",
    "* Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1 - Guidelines for Prompting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup \n",
    "## Load the API Key and Necessary Python Libraries\n",
    "\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "# you have build the model this will help to get the results for your prompt\n",
    "def get_result(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\" : prompt}]\n",
    "    response = client.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages,\n",
    "        temperature = 0, # This is the degree of randomness of the model's output\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompting Principles\n",
    "* Principle 1: Write clear and specific instructions\n",
    "* Principle 2: Give the model time to \"think\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To achieve the desired output from a model, provide clear and specific instructions, as longer prompts often offer more clarity and context, reducing the likelihood of irrelevant or incorrect responses.\n"
     ]
    }
   ],
   "source": [
    "### Principle 1:\n",
    "\n",
    "text = f\"\"\"\n",
    "You should express what you want a model to do by \\ \n",
    "providing instructions that are as clear and \\ \n",
    "specific as you can possibly make them. \\ \n",
    "This will guide the model towards the desired output, \\ \n",
    "and reduce the chances of receiving irrelevant \\ \n",
    "or incorrect responses. Don't confuse writing a \\ \n",
    "clear prompt with writing a short prompt. \\ \n",
    "In many cases, longer prompts provide more clarity \\ \n",
    "and context for the model, which can lead to \\ \n",
    "more detailed and relevant outputs.\n",
    "\"\"\"\n",
    "prompt = f\"\"\"\n",
    "Summarize the text delimited by triple backticks \\ \n",
    "into a single sentence.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "result = get_result(prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Principle 2:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
